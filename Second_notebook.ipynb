{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of P100.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJbYXou6chZf"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXSDuqZ_CrAD"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3v9FGp7xhWI"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF-qif2XGtMV",
        "outputId": "5db094ec-540e-4e1f-cd55-f4b3e72d5373"
      },
      "source": [
        "df1 = pd.read_csv(\"Dataset1.csv\")\n",
        "df2 = pd.read_csv(\"Dataset2.csv\")\n",
        "df2.drop('Timestamp',axis=1,inplace=True)\n",
        "df2.columns = ['Tell me about yourself',\n",
        "       'Tell me about a time you demonstrated leadership',\n",
        "       'Tell me about a time when your working on a team and faced with a challenge how did you solve that problem?',\n",
        "       'tell me about one of your weaknesses and how you plan to overcome it.',\n",
        "       'Now why do you think we should hire you?', 'Label']\n",
        "df = df1.append(df2,ignore_index=True)\n",
        "#df = pd.read_csv(\"Dataset3.csv\")\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(162, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cplejGkP_ibP"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrjVb1nkMvJ3"
      },
      "source": [
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "def clean(mytext):\n",
        "  tokens = []\n",
        "  nlp = spacy.load('en',parser=False,entity=False)\n",
        "\n",
        "  #spacy customize stopwords  \n",
        "  # New stop words list \n",
        "  customize_stop_words = [\n",
        "      '.',\n",
        "      '-',\n",
        "      '.....',\n",
        "      '....'\n",
        "      ]\n",
        "  # Mark them as stop words\n",
        "  for w in customize_stop_words:\n",
        "      nlp.vocab[w].is_stop = True\n",
        "\n",
        "  my_doc = nlp(mytext)\n",
        "  for token in my_doc:\n",
        "    if not token.is_stop:\n",
        "      tokens.append(token.lemma_)\n",
        "  \n",
        "  return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3SUUk06Gw3I"
      },
      "source": [
        "mylist = []\n",
        "for i in range(len(df)):\n",
        "  text = ''\n",
        "  for j in range(len(df.iloc[i])-1):\n",
        "    text+=re.sub(r'\\|Interviewe(r|e): | \\[.*\\] | \\(.*\\) | \\{.*\\} | \\.*',' ',df.iloc[i][j],flags=re.IGNORECASE)\n",
        "  mylist.append((df.iloc[i][5],\" \".join(clean(text))))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6fLgYzxQj0-"
      },
      "source": [
        "mydf = pd.DataFrame(mylist,columns=['Label','Reponses'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHAuVsi4Q9Sr",
        "outputId": "404bea85-cd8d-4f37-889e-d087f4faa076"
      },
      "source": [
        "mydf.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(162, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPuxTs65FQVm"
      },
      "source": [
        "#try a BERT model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtKr75SiC4ID"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XyCj2zPVRGRV",
        "outputId": "0ed78bdb-13e5-434b-b1f1-3c4d7dbcf724"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGEbgYTrUh3z"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8DXKReqfnWx",
        "outputId": "d9acd030-4853-4648-eff0-e5e66de32af9"
      },
      "source": [
        "#divide into train test spilt\n",
        "def load_data(dataframe,split_ratio):\n",
        "  #shuffle the data\n",
        "  data = dataframe.sample(frac=1,random_state=7)\n",
        "\n",
        "  texts = data.Reponses.values\n",
        "  labels = [{'cats': {'2': label == 2,\n",
        "                      '3': label == 3,\n",
        "                      '4': label == 4,\n",
        "                      '5': label == 5\n",
        "                      }\n",
        "            } for label in data['Label']]\n",
        "\n",
        "  split = int(len(data) * split_ratio)\n",
        "    \n",
        "  return texts[:split], labels[:split], texts[split:], labels[split:]\n",
        "\n",
        "train_data,train_labels,val_data,val_labels = load_data(mydf,0.8)\n",
        "\n",
        "print(train_data.shape,val_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(129,) (33,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzy_QuilIHV9"
      },
      "source": [
        "temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "1Mtxj1t7HzN7",
        "outputId": "905b45c9-309a-4815-915c-49ed9b1eeefb"
      },
      "source": [
        "temp = mydf['Label']\n",
        "temp = list(temp)\n",
        "classes = 4\n",
        "encoded = np.eye(classes)[temp]\n",
        "encoded"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-aafcd3c95fde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBDCk7dJEsi_",
        "outputId": "ac04be09-ced2-4d07-e9f1-c9ad94722847"
      },
      "source": [
        "from numpy import array\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "labels = mydf['Label']\n",
        "data = array(labels)\n",
        "\n",
        "encoded = [[]]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhxk0LLYinlT"
      },
      "source": [
        "train_zip = list(zip(train_data, train_labels))\n",
        "val_zip = list(zip(val_data, val_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hddbbvaGWiA5"
      },
      "source": [
        "#spacy supervised model\n",
        "nlp = spacy.blank(\"en\")\n",
        "# Create the TextCategorizer with exclusive classes and \"bow\" architecture\n",
        "textcat = nlp.create_pipe(\n",
        "              \"textcat\",\n",
        "              config={\n",
        "                \"exclusive_classes\": True,\n",
        "                \"architecture\": \"bow\"})\n",
        "\n",
        "# Add the TextCategorizer to the empty model\n",
        "nlp.add_pipe(textcat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyFNuz1Pc32i",
        "outputId": "1fce77b5-20cc-451a-bccd-47b34ec91ea2"
      },
      "source": [
        "# Add labels to text classifier\n",
        "textcat.add_label(\"2\")\n",
        "textcat.add_label(\"3\")\n",
        "textcat.add_label(\"4\")\n",
        "textcat.add_label(\"5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSWHSp_6eyn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fb0a8e9-a59c-441e-c5b6-c4c6c8a0e53d"
      },
      "source": [
        "import random\n",
        "from spacy.util import minibatch\n",
        "\n",
        "random.seed(1)\n",
        "spacy.util.fix_random_seed(1)\n",
        "optimizer = nlp.begin_training()\n",
        "\n",
        "losses = {}\n",
        "for epoch in range(20):\n",
        "    random.shuffle(train_zip)\n",
        "    # Create the batch generator with batch size = 8\n",
        "    batches = minibatch(train_zip, size=8)\n",
        "    # Iterate through minibatches\n",
        "    for batch in batches:\n",
        "        # Each batch is a list of (text, label) but we need to\n",
        "        # send separate lists for texts and labels to update().\n",
        "        # This is a quick way to split a list of tuples into lists\n",
        "        texts, labels = zip(*batch)\n",
        "        nlp.update(texts, labels, sgd=optimizer, losses=losses)\n",
        "    print(losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'textcat': 1.6318165543489158}\n",
            "{'textcat': 2.042804362718016}\n",
            "{'textcat': 2.0749434651133924}\n",
            "{'textcat': 2.1790675607826415}\n",
            "{'textcat': 2.2459526215770893}\n",
            "{'textcat': 2.2519719772972167}\n",
            "{'textcat': 2.253616067171606}\n",
            "{'textcat': 2.2579116714653082}\n",
            "{'textcat': 2.2580348983043095}\n",
            "{'textcat': 2.264004411544782}\n",
            "{'textcat': 2.264067159791942}\n",
            "{'textcat': 2.264437456205421}\n",
            "{'textcat': 2.2644620694440505}\n",
            "{'textcat': 2.264507842774549}\n",
            "{'textcat': 2.264523770080075}\n",
            "{'textcat': 2.264632078150118}\n",
            "{'textcat': 2.264642749306997}\n",
            "{'textcat': 2.264651459505952}\n",
            "{'textcat': 2.2646682447263053}\n",
            "{'textcat': 2.26467409677164}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZc4t691UzMv"
      },
      "source": [
        "#try saving the model\n",
        "nlp.to_disk('/content/myModel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AVitk5GU_9G"
      },
      "source": [
        "#load the model\n",
        "myModel = spacy.load('/content/myModel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMGP7BzGaUG0"
      },
      "source": [
        "def predict(nlp,texts):\n",
        "  docs = [nlp.tokenizer(text) for text in texts]\n",
        "  textcat = nlp.get_pipe('textcat')\n",
        "  score,tensor = textcat.predict(docs)\n",
        "  predicted_class = score.argmax(axis=1)\n",
        "  return predicted_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBumTqXUf5aE"
      },
      "source": [
        "def evaluate(model,texts,labels):\n",
        "  predicted_class = predict(model,texts)\n",
        "  true_class = []\n",
        "  for i in range(len(labels)):\n",
        "    true_class.append(list(labels[i]['cats'].values()).index(True))\n",
        "\n",
        "  #print(true_class[:10],predicted_class[:10])\n",
        "\n",
        "  correct_predictions = predicted_class == true_class\n",
        "\n",
        "  #print(correct_predictions[:10])\n",
        "\n",
        "  return correct_predictions.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T45HPw8TsIbT"
      },
      "source": [
        "accuracy = evaluate(nlp, val_data, val_labels)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC3FLzMEHibd"
      },
      "source": [
        "#bow = 0.5848\n",
        "#ensemble = 0.3636\n",
        "#CNN = 0.4545\n",
        "\n",
        "val_labels[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CsXEDR1GoKz"
      },
      "source": [
        "texts = val_data[:10]\n",
        "predictions = predict(myModel1, texts)\n",
        "\n",
        "for p, t in zip(predictions, texts):\n",
        "    print(f\"{textcat.labels[p]}: {t} \\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27HSvg7jfDcF",
        "outputId": "a23befff-b40b-46b6-ea19-fc15b31b6d5b"
      },
      "source": [
        "#shows the probabilities for each class\n",
        "mydoc = nlp(to_predict)\n",
        "mydoc.cats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': 0.0021423092111945152,\n",
              " '2': 0.003565057646483183,\n",
              " '3': 0.9886618852615356,\n",
              " '4': 0.0037832744419574738,\n",
              " '5': 0.001847579376772046}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "_M7kY_dFOZkq",
        "outputId": "815eba47-75a1-4cd7-c73a-afb34bbbe1e4"
      },
      "source": [
        "first = [\"My name is Vedant and I'm 21 years old. I am in my last year of engineering. I love to uhmm play sports, read books, watch series and movies , and listen to songs in my spare time.\"]\n",
        "second = [\"uhm...This happened about 3 years back when I was in FE. We were playing quarter finals of a tournament and we're comfortably leading 2-0. All of a sudden our team lost concentration and we conceded 2 goals in 5'. Everyone seemed demotivated. This is when I tried to motivate them and in trying to do so scored a goal which for their spirits back up. We ended up winning the game 4-2.\"]\n",
        "third = [\"It was our mini project submission and we were getting an error. After calling up around 5-6 friends my team and I couldn't solve the error. So we were thinking of restarting the whole project and I just told them to calm down and look at the code once again. We found the root of the error and thankfully it got solved.\"]\n",
        "fourth = [\"One weakness I've is I get short tempered when we're working as a team and I don't see 100% efforts from my  team to win a match/ complete a task. I'm of the opinion that efforts matter more than results. But after thinking alot I feel that sometimes results are as important as efforts. So I'm trying to overcome this thing.\"]\n",
        "fifth = [\"I possess all the skills and experience that you're looking for. I'm pretty confident that I am the best candidate for this job role. It's not just my background in the past projects, but also my people skills, which will be applicable in this position. With my experience in extra curricular I might even be able to give a different angle to some situations\"]\n",
        "\n",
        "temp = first + second + third + fourth + fifth\n",
        "testText = \" \".join(temp)\n",
        "testText"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"My name is Vedant and I'm 21 years old. I am in my last year of engineering. I love to uhmm play sports, read books, watch series and movies , and listen to songs in my spare time. uhm...This happened about 3 years back when I was in FE. We were playing quarter finals of a tournament and we're comfortably leading 2-0. All of a sudden our team lost concentration and we conceded 2 goals in 5'. Everyone seemed demotivated. This is when I tried to motivate them and in trying to do so scored a goal which for their spirits back up. We ended up winning the game 4-2. It was our mini project submission and we were getting an error. After calling up around 5-6 friends my team and I couldn't solve the error. So we were thinking of restarting the whole project and I just told them to calm down and look at the code once again. We found the root of the error and thankfully it got solved. One weakness I've is I get short tempered when we're working as a team and I don't see 100% efforts from my  team to win a match/ complete a task. I'm of the opinion that efforts matter more than results. But after thinking alot I feel that sometimes results are as important as efforts. So I'm trying to overcome this thing. I possess all the skills and experience that you're looking for. I'm pretty confident that I am the best candidate for this job role. It's not just my background in the past projects, but also my people skills, which will be applicable in this position. With my experience in extra curricular I might even be able to give a different angle to some situations\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFxLQbqTRkJq"
      },
      "source": [
        "to_predict = \" \".join(clean(testText))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWJlIbNmZq6O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nqr9lxAIj4f"
      },
      "source": [
        "import cv2\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8xZedy2Jr4x"
      },
      "source": [
        "classifier_path_face = '/usr/local/lib/python3.7/dist-packages/cv2/data/haarcascade_frontalface_alt.xml'\n",
        "classifier_path_eye = '/usr/local/lib/python3.7/dist-packages/cv2/data/haarcascade_eye.xml'\n",
        "image_path = '/content/apala2.jpeg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3YURj97NZfc"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def face_eye_detection(image_path,face_classifier_path,eye_classifier_path):\n",
        "  original_image = cv2.imread(image_path)\n",
        "  gray_image = cv2.cvtColor(original_image,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  face_classifier = cv2.CascadeClassifier(face_classifier_path)\n",
        "  eye_classifier = cv2.CascadeClassifier(eye_classifier_path)\n",
        "\n",
        "  faces = face_classifier.detectMultiScale(gray_image,1.3,5)\n",
        "\n",
        "  for (column,row,width,height) in faces:\n",
        "    cv2.rectangle(original_image,(column,row),(column+width,row+height),(0,255,0),2)\n",
        "\n",
        "    #roi_color = original_image[row:row+height,column:column+width]\n",
        "    #roi_gray = gray_image[row:row+height,column:column+width]\n",
        "\n",
        "    #face_gray_image = cv2.cvtColor(face_image,cv2.COLOR_BGR2GRAY)\n",
        "    eyes = eye_classifier.detectMultiScale(gray_image)\n",
        "    for (ecolumn,erow,ewidth,eheight) in eyes:\n",
        "      cv2.rectangle(original_image,(ecolumn,erow),(ecolumn+ewidth,erow+eheight),(255,0,0),2)\n",
        "  \n",
        "  fname, ext = os.path.splitext(image_path)\n",
        "  cv2.imwrite(fname+\"_cropped\"+ext,original_image)\n",
        "  #cv2_imshow(original_image)\n",
        "  return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1XtifX8PnTx"
      },
      "source": [
        "face_eye_detection(image_path,classifier_path_eye,classifier_path_face)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRteWeJ8PmlH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j79pLFuFOL4U",
        "outputId": "d1497d4b-e638-412b-9cfd-cf195d977889"
      },
      "source": [
        "import os\n",
        "fname,ext = os.path.splitext(image_path)\n",
        "print(fname,ext)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/jokers .png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5H7sccVLkLy"
      },
      "source": [
        "def detectface(image,classifier):\n",
        "  #read the image\n",
        "  original_image = cv2.imread(image)\n",
        "\n",
        "  #convert it to grayscale\n",
        "  gray_scale = cv2.cvtColor(original_image,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  #load the classifier\n",
        "  face_cascade = cv2.CascadeClassifier(classifier)\n",
        "  detected_faces = face_cascade.detectMultiScale(gray_scale)\n",
        "  #counter = 0\n",
        "\n",
        "  if detected_faces is ():\n",
        "    print('No face detected')\n",
        "  else:\n",
        "    for (column,row,width,height) in detected_faces:\n",
        "      image = cv2.rectangle(original_image,(column,row),(column+width,row+height),(0,255,0),2)\n",
        "      fname, ext = os.path.splitext(image_path)\n",
        "      cv2.imwrite(fname+\"_detected\"+str(counter)+ext,image)\n",
        "      #counter+=1\n",
        "  return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8F5wnniO7bs",
        "outputId": "34155057-bc2e-4934-9295-cd02a210fc85"
      },
      "source": [
        "detectface(image_path,classifier_path_face)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No face detected\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ5WqMZfO_hm"
      },
      "source": [
        "classifier_path_eye = '/usr/local/lib/python3.7/dist-packages/cv2/data/haarcascade_eye.xml'\n",
        "def detecteyes(image,classifier):\n",
        "  original_image = cv2.imread(image)\n",
        "  gray_scale = cv2.cvtColor(original_image,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  eye_cascade = cv2.CascadeClassifier(classifier)\n",
        "  detected_eyes = eye_cascade.detectMultiScale(gray_scale)\n",
        "\n",
        "  \n",
        "  for (column,row,width,height) in detected_eyes:\n",
        "    print(column,row,width,height)\n",
        "    image = cv2.rectangle(original_image,(column,row),(column+width,row+height),(0,255,0),2)\n",
        "    fname, ext = os.path.splitext(image_path)\n",
        "    cv2.imwrite(fname+\"_detected\"+ext,image)\n",
        "\n",
        "  return\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-83aKQ1TiNJ",
        "outputId": "050421b5-5361-4802-f3bc-b9f3813c7c62"
      },
      "source": [
        "detecteyes(image_path,classifier_path_eye)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "209 209 25 25\n",
            "255 209 27 27\n",
            "351 242 29 29\n",
            "474 239 32 32\n",
            "385 244 31 31\n",
            "519 241 34 34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg1sfXGpUchx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}